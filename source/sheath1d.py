"""A one-dimensional ion formation, recombination, and transport model

Sheath1D is a base class used to build child classes with their own methods for 
constructing the model under a less general set of assumptions.

** THE PROBLEM **
There are presumed to be two charged species (one + and one -) that are modeled
with the following limiting assumptions in one dimension:
    (1) uniform diffusion and mobility coefficients
    (2) uniform temperature
    (3) velocity, u(z), is nonzero, but vanishes at z=0
    (4) ion formation, w(z), is nonzero, but vanishes at z->1

The solutions are dimensionless and over a dimensionless domain.  The spatial 
dimension, z, always ranges from 0 to 1, and corresponds to a physical domain
from 0 to infinity.  This is accomplished by a logarithmic scaling,

    x = -L ln(1-z)
    
where L is the Debye length.

The dimensionless positive ion number density, eta, and electron number density,
nu, are zero at z=0 and unity at z=1.  The electric field strength, psi, is 
specified at z=1 and uniform at z=0.

The governing equations are:
    0 = -R u(z) eta' + (1-z) eta'' + tau (eta psi)' + omega/(1-z) w(z)  (1)
    0 = -Re u(z) nu' +  (1-z) nu'' - (nu psi)' + omega/(mu (1-z)) w(z)  (2)
    0 = (1-z) psi' + nu - eta                                           (3)

Dimensionless model parameters are:
    R       Reynolds number (for + ion)
    Re      Reynolds number (for - ion) = R / mu
    mu      ion mobility ratio (mu- T- / mu+ T+)
    tau     ion temperature ratio (T- / T+)
    omega   local dimensionless ion formation rate

Nonlinearity in the problem is quadratic from the electrical mobility terms 
(eta phi')' and (nu phi')' and from the recombination term beta eta nu. Once 
a method of finite differences is applied, the general form of the problem is

    0 = C + L*X + X*Q*X

where
X   := Solution vector = [eta nu phi] (3N)
C   := Constant vector (3N)
L   := Linear matrix (3N x 3N)
Q   := Quadratic tensor (3N x 3N x 3N)

The solution vector, X, is an ordered concatenation of the eta (dimensionless 
ion concentration), nu (dimensionless electron concentration), and phi 
(dimensionless electric potential).  If there are N nodes in the system, then
the dimensions of these vectors, matrices, and tensors will be as shown.
All nonlinearity is included in the Q tensor.

** ERROR **
The error, E, for the governing equations at each node is calculated

    E = C + L*X + X*Q*X

where
E   := Error vector = [etaE nuE phiE] (3N)

The error vector, E, is an ordered concatenation of the species conservation
equations (etaE and nuE) and the Poisson equation (phiE) applied to each node.

** SOLUTION METHOD **
The step_solution() method uses a Newton solver by performing linear expansion
about X => X + dX

    0 = C + L*(X+dX) + (X+dX)*Q*(X+dX)
      = (C + L*X + X*Q*X) + L*dX + dX*Q*X + X*Q*dX + ...
      = E + (L + Q*X + Q.transpose(1,2)*X) * dX
So, 
    -E = (L + QQT*X) * dX
where
QQT := Symmetrical quadratic tensor = Q + Q.transpose(1,2) (3N x 3N x 3N)

The QQT tensor is an intermediate coefficient that is calculated in advance to
speed the Newton solution method.

** MEMBERS **
These are the data members of the Ion1D class and its child classes.

MEMBER      DESCRIPTION
param       An object with child-class-specific parameters used to construct
            the model matrices/tensors.
            
post        A dictionary of post-processed parameters generated by the 
            init_post() method.

z           A Numpy array of node locations in the domain [0,1].  Initialized
            by the a child class method: init_grid()

X           The solution vector containing eta, nu, and phi at each node, 
            defined as a numpy array.

E           The error vector containing errors for the governing equations for
            eta, nu, and phi as a numpy array.

eta         eta, nu, and phi are numpy arrays of the respective solution values
nu          at each node.  These point inside of the original X array.
phi

etaE        Numpy arrays of errors for the governing equations for eta, nu, and
nuE         phi.  These point inside the original E array.
phiE

initstate   The initialization state index for the model (see below)

C, L, Q     The model vector, matrix, and tensor defining the problem (see below)

QQT         An intermediate tensor for the solution algorithm (see below)

** SOLUTION PROCESS **
The model tracks its own progress in the solution process by the INITSTATE
member.  This allows the solution to be conducted in steps so the application 
can override defaults, diagnose problems, or monitor progress between each step.
The following shows the class methods that affect the INITSTATE, lists the init
state requirements, and lists the member data elements affected.

__init__()
    require initstate:  None
    result initstate:   0
    require members:    None
    write members:      param
      Initializes the entire data struct, but sets most members to None by 
    default (see below).  The param member object is initialized to default 
    values.  Child classes may augment those values as necessary.

init_param()
    require initstate:  0
    result initstate:   Child-dependent
    require members:    param
    write members:      param
     Child-specific init_param() methods write parameter members to the param
    attribute.  Where and how these are used are entirely up to the child.
    
init_grid()
    require initstate:  0
    result initstate:   1
    require members:    Child-dependent (usually param)
    write members:      z
      Child-specific init_grid() methods are responsible for defining an array
    in the z-attribute which locates all of the nodes in the domain.
    
init_mat()
    require initstate:  1
    result initstate:   2
    require members:    Child-dependent (usually param, z)
    write members:      C, L, Q, QQT
      Child-specific init_mat() methods are responsible for calculating the 
    problem's tensors that will be used to solve the system.
    
init_solution()
    require initstate:  2
    result initstate:   3
    require members:    param, z
    write members:      X, E, eta, nu, phi, etaE, nuE, phiE
      The generic Ion1D, child-specific, or user defined solution initialization
    methods are responsible for producing an initial guess for the solution
    vector, X, and calculating an initial error from the problem tensors C, L, 
    and Q.  eta, nu, and phi are set to point into the master array, X.  etaE,
    nuE, and phiE are similarly pointed into the master error array, E.

step_solution()
    require initstate:  3
    result initstate:   3
    require members:    E, X, C, L, Q, QQT
    write members:      E, X, eta, nu, phi, etaE, nuE, phiE
      The generic Ion1D step_solution() method performs a single Newton solver
    step and calculates a new error vector.  The intention is that a user or
    application will repeatedly call this method until the solution has 
    converged.  Convergence can be tested manually by plotting the solution 
    with show_solution() (see below), or a custom convergence test could be
    written.

show_solution()
    require initstate:  3
    result initstate:   3
    require members:    eta, nu, phi, etaE, nuE, phiE
    write members:      eta, nu, phi, etaE, nuE, phiE
      Produces a plot of the solutions and their error values over the domain.

init_post()
    require initstate:  3
    result initstate:   4
    require members:    z, eta, nu, phi, etaE, nuE, phiE
    write members:      post
      Once a solution has converged, init_post() can be called to generate a
    number of potentially valuable vectors over the solution domain.  These are
    written to the post meber dictionary.

If the initstate is lower than required, these methods will raise an exception
with instructions for correcting the issue.  If the initstate is higher than
required, the method will raise a warning and will demote the initstate by 
overwriting previous work.  For example, if init_grid() is called after a 
solution is already available, the tensors and solution will all be erased and
a new grid will be created, but the parameters will be unaffected.

CHANGELOG:
1.0     (2022-02-28)
Made a copy of the Ion1D code and began modifying for use as Sheath1D

"""

import numpy as np
from miscpy import sparsen as spn
from scipy import sparse as spsp
from scipy.sparse import linalg as spla
from miscpy import sparsen as spn
import matplotlib.pyplot as plt
import os, json, shutil, tempfile, tarfile
import sheath1d as _sheath1d

# Constants are in mks units
const_e = 1.6021765658368782e-19    # Fundamental charge
const_ep = 8.854187817e-12          # Permittivity of free space
const_k = 1.38064852e-23           # Botlzmann's constant


__version__ = '1.0'



def load_post(source, verbose=True, loadnpy=True, loadmodel=True, loadparam=True):
    """Load the post-processing results of a model run
    post = load_post('/path/to/source/dir')
    
The load_post() function is responsible for rebuilding the post dict saved by
the Ion1D class's save_post() member method.  This allows detailed results from
a model to be saved for later retrieval.

There are optional keywords that configure the behavior of load_post().  These
are their defaults and their behaviors...

verbose = True
Print a summary of data as it is being loaded.

loadnpy = True
If True, all strings that refer to a *.npy file in the post directory will be
loaded and converted to numpy array objects.  If False, they will be left as
strings

loadmodel = True
If True, the model string should be converted into the corresponding Ion1D class.
If False, it will be left as a string.

loadparam = True
If True, the param dictionary will be converted to an IonParam object.  If False,
it will be left as a dictionary.
"""
    # Force absolute paths
    source = os.path.abspath(source)
    # Verify that the source exists
    if not os.path.isdir(source):
        raise Exception('The source directory does not exist: ' + source)
    elif verbose:
        print('Found source directory: ' + source)
    # Load the base dictionary
    postfile = os.path.join(source, 'post.json')
    try:
        with open(postfile,'r') as ff:
            post = json.load(ff)
        if verbose:
            print('Loaded post file: ' + postfile)
    except:
        raise Exception('Failed to parse the post json file: ' + postfile)
        
    if loadparam and 'param' in post:
        post['param'] = IonParam(**post['param'])
        
    if loadmodel and 'model' in post:
        if post['model'] in __ion1d.__dict__:
            post['model'] = __ion1d.__dict__[post['model']]
        else:
            print('LOAD_POST::WARNING: Did not find the model: ' + repr(post['model']))
        
        
    if not loadnpy:
        return post
    
    # Go get the numpy array files
    for key,value in post.items():
        if isinstance(value,str):
            npfile = os.path.join(source,value)
            if verbose:
                print('Loading numpy file: ' + npfile)
            if os.path.isfile(npfile):
                try:
                    post[key] = np.load(npfile)
                except:
                    raise Exception('Failed to load the numpy file: ' + npfile)
            elif verbose:
                print('File not found: ' + npfile)
                print('String entry does not appear to be a numpy file: post["%s"] = %s'%(key,value))
    return post


def cubicgrid(N, r1=1., r2=1., start=True, stop=True):
    """Return a series of node locations ranging from 0 to 1 with cubic spacing

cubicgrid(N, r1=1., r2=1., start=True, stop=True)

N   total number of elements (N+1 nodes)
    When the start and stop nodes are included, there will be N+1 total values
    returned, representing a set of N elements (regions between nodes).

r1  relative distance between nodes at the start
r2  relative distance between nodes at the stop
    r1 and r2 are used to modify the distribution of node locations.  When r1 
    and r2 are both 1, the node will be uniformly distributed.  When r1 or r2 
    are greater than 1, the nodes near the respective end of the node will be
    more widly spaced by the corresponding factor.  For example, setting r1 to
    0.5 and r2 to 1 would double the node spacing at the start and keep the 
    nominal spacing at the stop.
    
    Because the node distribution is generated from a cubic polynomial, the 
    node density at the center will be implicitly adjusted by r1 and r2 so that
    the relative space at the center will be d0.5 = 1.5 - 0.25*(r1 + r2).  
    Obviously, if r1 and r2 sum to greater than 6, there is a problem; the 
    center node spacing will be negative.
    
    The values of r1 and r2 are used to check the minimum spacing in the domain.
    If the minimum spacing is found to be negative, then an error is raised.  As
    a general rule of thumb, if r1 and r2 are each 3 or less, there will not be
    a problem.

start   include the first point?
stop    include the last point?

"""
    # Test for nonnegative r1 r2
    if r1 < 0 or r2 < 0:
        raise Exception('r1 and r2 must be positive.')
    # Test for monotonicity
    if r1 + r2 > 2:
        # find the minimum slope point
        xm = ((2./3.)*r1 + (1./3.)*r2 - 1.) / (r1 + r2 - 2)
        # If it is in the domain
        if 0 <= xm <= 1:
            # Calculate the slope there
            zprime = 1 + (r1-1.) * ((3*xm - 4)*xm + 1) \
                    - (r2-1.) * ((-3*xm + 2) * xm)
            # If negative, raise an error
            if zprime < 0:
                raise Exception('The sub-domain contains negative spacing. Reduce the spacing at the ends.')

    if start and stop:
        x = np.linspace(0,1,N+1)
    elif stop:
        x = np.linspace(1./N, 1, N)
    elif start:
        x = np.linspace(0, (N-1.)/N, N)
    else:
        x = np.linspace(1./N, (N-1.)/N, N-1)
    x_1 = 1-x
    xx_1 = x * x_1
    return x + (r1-1.) * xx_1 * x_1 - (r2-1.) * xx_1 * x


class IonParam:
    """Ion Parameter Class
This is a thin structure for initializing and retreiving the model parameters.
There are generic parameters that are relevant to every model (listed below),
but the child Ion1D classes can add their own parameters on the fly or at
initialization.

To simply initialize empty
    param = IonParam()
    
To override defaults, just add the appropriate keyword argument.  Absent keyword
arguments will be left at their default values.
    param = IonParam(R=3000., tau=10.)

"""
    def __init__(self, **kwarg):
        self.__dict__.update(kwarg)
        
    def __repr__(self):
        out = 'IonParam('
        nfirst = False
        for param,value in self.__dict__.items():
            if nfirst:
                out += ', ' + param + '=' + str(value)
            else:
                out += param + '=' + str(value)
                nfirst = True
        out += ')'
        return out
        
    def __in__(self, key):
        return key in self.__dict__
        
    def __str__(self):
        out = '<IonParam object> with parameters:\n'
        for param,value in self.__dict__.items():
            out += '  %10s %f\n'%(param,value)
        return out

    def asdict(self):
        """Return the object as a dictionary
Returns self.__dict__
Changes to the returned dictionary are reflected by the object"""
        return self.__dict__
        
    def set(self, values):
        """Set parameters from a dictionary or another IonParam object
    set( P )
        OR
    set( {'beta':20., 'alpha':5e-4} )
when P is an IonParam object.
"""
        if isinstance(values, IonParam):
            self.__dict__.update(values.__dict__)
        elif isinstance(values, dict):
            self.__dict__.update(values)
        else:
            raise Exception('IonParam.set(): Expected IonParam or dict instance. Got: {:s}'.format(repr(values)))
            
    def get_header(self, colwidth=18):
        """Generate a string header for generating tables of parameters
    header = P.get_header(colwidth=18)

The header will be constructed from the parameter data member names left-
justified in columns colwidth apart.  The names are ordered alphabetically
so that they will agree with the lines returned by the get_entry() method.

See also the get_entry() method."""
        kk = list(self.__dict__.keys())
        kk.sort()
        # build the format specifier
        fmt = '{{:<{:d}s}}'.format(colwidth)
        out = ''
        for key in kk:
            out += fmt.format(key)
        return out
        
        
    def get_entry(self, colwidth=18):
        """Generate a string line entry for a table of parameters
    entry = P.get_entry(colwidth=18)

The entry will be a space-separated string of floating point values for every 
parameter included in the IonParam object.  The entries are sorted by member
name alphabetically, so they will always be in the same order.

See also the get_header() method."""
        kk = list(self.__dict__.keys())
        kk.sort()
        # build the format specifier
        fmt = '{{:<{:d}.8e}}'.format(colwidth)
        out = ''
        for key in kk:
            out += fmt.format(self.__dict__[key])
        return out
        


class IonParamManager:
    """A class for automating the solution of an Ion1D model over many parameters
The intended use for an IPM is to automate iteration of a series of many 
IonParam objects without requiring that each IonParam object be created in 
advance.  Instead, individual parameters can be written or read as scalars or
arrays and the IonParam objects will be generated on the fly as needed.

An IonParamManager may be initialized in three different ways:
    # From keyword arguments of array-like and scalar values
    ipm = IonParamManager(phia=np.arange(-10,20,2), beta=50.)
        OR
    # To make an independent copy of another IonParamManager
    ipm = IonParamManager(ipm2)
        OR
    # From a dictionary of array-like and scalar values
    ipm = IonParamManager({'phia':[0,2,4,6], 'alpha':[1e-3, 5e-4, 2e-4, 1e-4]})

Alternately, a combination of these may be used.
    # e.g. to make a copy of an existing IPM with modified values
    ipm = IonParamManager(ipm2, R=3000.)
    
All array-like elements are expected to be the same length, and all other 
elements are interpreted as scalars.  IonParam objects can be generated on the
fly using the buildparam() method.  Scalars are assumed to remain constant for 
all cases, while arrays values are indexed by the buildparam() argument.

    ipm = IonParamManager(a=[0,1,2,3], b=3.1416)
    ipm.buildparam(0)
    # returns IonParam(a=0, b=3.1416) instance
    ipm.buildparam(3)
    # returns IonParam(a=3, b=3.1416) instance
    len(ipm)
    # return 4, equivalent to ipm.size

Since buildparam() works "on-the-fly" an IPM instance may be edited right up to
the point that parameters are created without deleterious effects

    ipm = IonParamManager(junk=[-1,-2,-3], b=3.1416)
    del ipm['junk']
    # Now, ipm has length 1
    ipm['a'] = [0,1,2,3]
    print(ipm['b'])
    # prints 3.1416
    
The IonParamManager class supports iteration
    ipm = IonParamManager(a=[1,2], b=0)
    for p in ipm:
        print(repr(p))
    # prints:
    # IonParam(a=1, b=0)
    # IonParam(a=2, b=0)
    
And also supports zip-like or dict's items()-like iteration
    for ii,p in ipm.items():
        print(ii, repr(p))
    # prints:
    # 0 IonParam(a=1, b=0)
    # 1 IonParam(a=2, b=0)

The split() method creates N new IPM objects with subsets of the original data
that are as evenly divided as possible.
    ipm = IonParamManager(foo=[0,1,2,3], bar=14)
    ipm0, ipm1, ipm2 = ipm.split(3)
    
However, each child IPM still contains all of the data as the parent
    len(ipm0)
    # prints 4
    ipm1['foo']
    # returns [0,1,2,3]
    ipm2.buildparam(0)
    # returns IonParam(foo=0, bar=14)

Instead, it is their iteration behavior that is modified.
    for ii,p in ipm.items():
        print(ii, repr(p))
    # prints:
    # 0 IonParam(foo=0, bar=14)
    # 1 IonParam(foo=1, bar=14)
    # 2 IonParam(foo=2, bar=14)
    # 3 IonParam(foo=3, bar=14)
    for ii,p in ipm0.items():
        print(ii, repr(p))
    # prints:
    # 0 IonParam(foo=0, bar=14)
    for ii,p in ipm1.items():
        print(ii, repr(p))
    # 1 IonParam(foo=1, bar=14)
    # 2 IonParam(foo=2, bar=14)
"""
    def __init__(self, arg=None, **kwarg):
            
        # Initialize the members
        self.size = None        # A count of array elements
        self.pdict = kwarg  # The dictionary of parameters set at initialization
        self._startindex = None
        self._stopindex = None
        self._itercount = None  # Integer iteration counter

        if arg is not None:
            if isinstance(arg, IonParamManager):
                self.pdict.update(arg.pdict)
            elif isinstance(arg, dict):
                self.pdict.update(arg)
        
        # Convert all parameters to numpy arrays and determine the size of the case
        for key,value in self.pdict.items():
            if not np.isscalar(value):
                self.pdict[key] = np.asarray(value)
                thissize = self.pdict[key].size
                if self.size is None:
                    self.size = thissize
                elif self.size != thissize:
                    raise Exception('Array-like entries to the IonCaseManager parameters have dissimilar numbers of entries.')
        # What if none of the entries were array-like?
        # Well, that's pretty borring, but that's no reason to cause a crash
        if self.size is None:
            self.size = 1
        
        
    def __iter__(self):
        start = 0
        stop = self.size
        if self._startindex is not None:
            start = self._startindex
        if self._stopindex is not None:
            stop = self._stopindex
        for ii in range(start,stop):
            yield self.buildparam(ii)
        
    def __getitem__(self, index):
        return self.pdict[index]
        
    def __delitem__(self, index):
        # Are we deleting a scalar or an array?
        value = self.pdict[index]
        del self.pdict[index]
        # If we just deleted a scalar or the IPM is already length 1, skip the next check
        if np.isscalar(value) or self.size == 1:
            return
        # If we just deleted an array, check to see if there are any arrays left
        for value in self.pdict.values():
            if not np.isscalar(value):
                return
        self.size = 1
        
    def __setitem__(self, index, value):
        if not np.isscalar(value):
            value = np.asarray(value)
            if self.size == 1:
                self.size = value.size
            elif self.size != value.size:
                raise Exception('Attempted assignment to key "{:s}" with a mismatching array size.')
        self.pdict[index] = value
        
    def __len__(self):
        return self.size
        
    def buildparam(self, index):
        """Build an IonParam object
    p = ipm.buildparam(index)

Construct an IonParam object from an IonParamManager object for the parameter
combination selected by index.  All scalar parameters are added to the result
verbatim, while array parameters are indexed with [index].
"""
        if index<0 or index>=self.size:
            raise IndexError('BUILDPARAM::index is out of range or negative.')
        p = IonParam()
        for key,value in self.pdict.items():
            if np.isscalar(value):
                p.__dict__[key] = value
            else:
                p.__dict__[key] = value[index]
        return p
        
    def copy(self):
        """Generate a copy of the IPM object
    ipm2 = ipm.copy()
    
This is fundamentally different from using the method:
    ipm2 = IonParamManager(ipm)
    
The latter creates an independent copy, so the attributes are distinct:
    ipm2.pdict is ipm.pdict     # returns False
    
When this is done using copy(),
    ipm2.pdict is ipm.pdict     # returns True
    
And the following will alter BOTH ipm2 AND ipm
    ipm['b'] = -47.5
"""
        p = IonParamManager()
        p.pdict = self.pdict
        p.size = self.size
        return p
        
    def items(self):
        """Return an iterator like the dictionary items() method
When ipm is an IonParamManager instance,
    for ii,p in ipm.items():
        ... code here ...
    
Is equivalent to
    for ii in range(ipm.size):
        p = ipm.buildparam(ii)
        ... code here ...
"""
        start = 0
        stop = self.size
        if self._startindex is not None:
            start = self._startindex
        if self._stopindex is not None:
            stop = self._stopindex
        for ii in range(start,stop):
            yield (ii,self.buildparam(ii))
        
    def split(self, n):
        """Divide an IonParamManager instance into N sub-managers
    (ipm0, ipm1, ipm2, ... ) = ipm.split(N)

This is a useful tool when dividing up a set of parameter combinations to 
individual workers for parallel processing.  Each of the split IPMs share the
same pdict as the parent, but their _startindex and _stopindex attributes
are set so that they will only iterate over a subset of the data.
"""
        out = []
        start = 0
        for ii in range(n):
            out.append(self.copy())
            out[-1]._startindex = start
            start = round((ii+1)*self.size/n)
            out[-1]._stopindex = start
        return out


class Ion1D:
    """Prototype ion model class
Generic base cass.  See the module documentation for details.
"""
    initstate = None
    param = None
    
    z = None
    
    X = None
    E = None
    C = None
    L = None
    Q = None
    QQT = None
    
    eta = None
    nu = None
    phi = None
    etaE = None
    nuE = None
    phiE = None

    def __init__(self, initstate=None):
        if initstate is not None and hasattr(self,'initstate'):
            if self.initstate < initstate:
                raise Exception('__init__ cannot increase the initstate; only decrease.')
            elif self.initstate == initstate:
                # do nothing
                return
                
        if initstate is None:
            # Define the parameters
            self.param = IonParam()
            # Initialize a post-processing dictionary
            initstate = 0
        if initstate<4:
            # Clear the post-processing results
            self.post = {}
        # Clear the solution?
        if initstate<3:
            # Solution vector
            self.X = None
            # Error vector
            self.E = None
            self.ee = None
            # D-less parameter solutions
            self.eta = None
            self.nu = None
            self.phi = None
            # D-less parameter equation errors
            self.etaE = None
            self.nuE = None
            self.phiE = None
        # Clear the matrices?
        if initstate<2:                
            # Constant vector
            self.C = None
            # Linear matrix
            self.L = None
            # Quadratic tensor
            self.Q = None
        # Clear the grid?
        if initstate<1:
            self.z = None
        self.initstate = initstate
        
        # overloaded functions
        self.__len__ = self.size
        
        
    def size(self):
        if self.initstate<1:
            raise Exception('The grid of this model has not been defined.')
        return self.z.size

    def dz(self, index):
        """dz  Return the coefficients for the first derivative at index
    
    c, cp, cpp = dz(index)
    
Returns a three-element vector with the coefficients for estimating a 
derivative at index using the node values of itself and its neighbors.

    ---o-----o-----o---
      k-1    k    k+1

If the coordinate locations of the nodes are zk-1, zk, and zk+1, and 
their corresponding node values are yk-1, yk, and yk+1 respectively, the
derivative at k is estimated from a quadratic interpolation of the
domain.  

Interpolation functions for y(z) passing through the k-element, are
    y(z) = a(z) yk-1  +  b(z) yk  +  c(z) yk+1

              (z - zk)(z - zk+1)
     a(z) = ------------------------
            (zk-1 - zk)(zk-1 - zk+1)
            
              (z - zk-1)(z - zk+1)
     b(z) = ------------------------
             (zk - zk-1)(zk - zk+1)
             
               (z - zk)(z - zk-1)
     c(z) = -------------------------
             (zk+1 - zk)(zk+1 - zk-1)

The first derivatives evaluated at zk quantifies the contribution of 
each node value to the derivative of y(zk).

a'(zk) = (zk - zk+1) / (zk-1 - zk) (zk-1 - zk+1)
b'(zk) = (2zk - zk+1 - zk-1) / (zk - zk-1) (zk - zk+1)
c'(zk) = (zk - zk-1) / (zk+1 - zk) (zk+1 - zk-1)

The second derivative evaluated at zk quantifies the contribution of each
node value to the second derivative of y(zk)

a"(zk) = 2 / (zk-1 - zk) (zk-1 - zk+1)
b"(zk) = -2 / (zk - zk-1) (zk - zk+1)
c"(zk) = 2 / (zk+1 - zk) (zk+1 - zk-1)

"""
        d10 = self.z[index+1] - self.z[index]
        d0_1 = self.z[index] - self.z[index-1]
        d1_1 = d10 + d0_1
        c0 = np.array([0, 1, 0], dtype=float)
        c1 = np.array([
            -d10/d0_1/d1_1,
            1/d0_1 - 1/d10,
            d0_1/d1_1/d10])
        c2 = np.array([
            2/d0_1


    def init_solution(self, eta=None, nu=None, phi=None):
        """Initialize the solution vectors
    M.init_solution()

Initializes the following members:
    M.X
    M.eta
    M.nu
    M.phi
"""
        if self.initstate <2:
            raise Exception('It appears that the solution matrices have not been initialized.  Run init_mat() first.')
        elif self.initstate>=3:
            print("INIT_SOLUTION::WARNING:: Overwriting an existing solution.")
        N = self.z.size
        # Initialize a triangle function for eta and nu initialization
        triangle = None
        if nu is None or eta is None:
            triangle = np.concatenate((
                np.linspace(0,1,int(N//2+N%2)),
                np.linspace(1,0,int(N//2))))
                
        self.X = np.ndarray((3*N,))
        self.eta = self.X[:N]
        self.nu = self.X[N:2*N]
        self.phi = self.X[2*N:3*N]
        # Use default initialization unless values are explicitly given
        if eta is not None:
            self.eta[:] = eta
        else:
            self.eta[:] = triangle
        if nu is not None:
            self.nu[:] = nu
        else:
            self.nu[:] = triangle
        if phi is not None:
            self.phi[:] = phi
        else:
            self.phi[:] = np.linspace(self.param.phia,0,N)

        # Set about calculating the initial error
        # Initialize an error vector
        self.E = self.C.copy()
        np.add( self.E, \
                self.L.dot(1,0,self.X,asdense=True), \
                out=self.E)
        np.add( self.E, \
                self.Q.dot(2,0,self.X).dot(1,0,self.X,asdense=True), \
                out=self.E)
                
        self.etaE = self.E[0:N]
        self.nuE = self.E[N:2*N]
        self.phiE = self.E[2*N:3*N]
        
        self.ee = [np.dot(self.E,self.E)]
        self.initstate=3
            
    def step_solution(self, clamp = False):
        """Perform a solution step calculation
The solution, X, obeys
    0 = C + L*X + X*Q*X = E
    -E = (L + QQT*X)*dX
        when QQT = Q + Q.transpose(1,2)
    Xnew = X + dX
"""
        if self.initstate < 3:
            raise Exception('The solution does not appear to be initialized.  Call init_solution() first.')
        elif self.initstate > 3:
            print('STEP_SOLUTION::WARNING:: It appears that init_post() has already been run.  Erasing.')
            self.post = {}
            self.initstate = 3
        A = (self.L + self.QQT.dot(2,0,self.X,asdense=True))
        self.X -= np.linalg.solve(A,self.E)
        
        # Test for values less than zero.
        if clamp:
            II = np.logical_or(self.eta < 0, self.nu < 0)
            self.eta[II] = 0
            self.nu[II] = 0
            
        np.copyto(self.E, self.C)
        np.add( self.E, \
                self.L.dot(1,0,self.X, asdense=True),\
                out = self.E)
        np.add( self.E, \
                self.Q.dot(2,0,self.X).dot(1,0,self.X,asdense=True),\
                out = self.E)
                
        self.ee.append(np.dot(self.E,self.E))

    def show_solution(self, fig=None):
        """Plot the solution and solution error
    M.show_solution()
        OR
    M.show_solution(fig=figure_handle)

Plots eta, nu, and phi and their errors in subplots.
"""
        if self.initstate<3:
            raise Exception('The solution has not been initialized. Run init_solution() and step_solution() first.')
        if fig is None:
            fig = plt.figure()
        fig.clf()
        ax_sol = fig.add_subplot(2,1,1)
        ax_err = fig.add_subplot(2,1,2)
        
        ax_sol.plot(self.z, self.eta, 'k', label='H$_3$O$^+$')
        ax_sol.plot(self.z, self.nu, 'k--', label='e$^-$')
        ax_sol.plot(self.z, self.phi, 'k:', label='V')
        ax_sol.legend(loc=0)
        
        ax_err.plot(self.z, self.etaE, 'k')
        ax_err.plot(self.z, self.nuE, 'k--')
        ax_err.plot(self.z, self.phiE, 'k:')
        
        plt.show()
        
    def test_solution(self, ep=1e-6):
        """Returns True if the solution has converged and raises an exception 
if the solution is diverging"""
        # Fail if the error energy is greater than a threshold
        if self.ee[-1] > 3*self.z.size*ep*ep:
            return False
        # If there are at least three error energies in the record
        if len(self.ee)>2:
            # Fail if the error energy is reducing steadily
            if self.ee[-3] > self.ee[-2] > self.ee[-1]:
                return False
            # If the error energy is increasing steadily, raise a divergence exception
            if self.ee[-3] < self.ee[-2] < self.ee[-1]:
                raise Exception('The solution is diverging.')
        # Pass... the solution has converged
        return True
        
    def init_post(self):
        """Spawn a PostIon1D instance for the solution results
    P = M.init_post()
        
Is equivalent to P = PostIon1D(M)
"""
        return PostIon1D(self)
        
        
class Sheath1D(Ion1D):
    """The Sheath1D class models the sheath in a stagnation problem
    
An execution of the model might appear
>>> M = FiniteIon1D()
>>> M.init_param( z1, z2, ... other params ...)
>>> M.init_grid( ... )
>>> M.init_mat()
>>> M.init_solution()
>>> while not M.test_solution():
...     M.step_solution()
Creates a model with a uniform ion generation region between z1 and z2 with
ion generation rate 1/(z2-z1).  By necessity, 0 <= z1 < z2 <= 1.
"""
    def __init__(self):
        # Initialize the general members
        Ion1D.__init__(self)
        # Add an attribute for keeping track of important indices
        self.k = None
        
    def init_param(self, arg=None, **kwarg):
        """FiniteIon1D model parameter initialization
    M.init_param(z1=z1, z2=z2, ...)
        OR
    M.init_param( param_obj )
        OR
    M.init_param({'z1':z1, 'z2':z2, ...})
    
init_param() accepts individual keyword, value pairs or an IonParam object, or
a dictionary with keyword, value pairs.

Required parameters:
z1, z2      These are the locations where the formation region begins and ends.
            init_param enforces  0 < z1 < z2 < 1
            
Optional parameters and their defaults:
R           Positive ion Reynolds number (2500.)
alpha       Dimensionless Debye length (1e-3)
beta        Dimensionless inverse recombination length (10.)
mu          Negative-to-positive species mobility ratio (200.)
tau         Negative-to-positive temperature ratio (1.)
phia        Dimensionless applied voltage (0.)

Derived parameters:
omega       Formation rate = 1./(z2-z1).  User values are overwritten.
"""
        if self.initstate > 0:
            print('INIT_PARAM::WARNING: Parameters already seem to be implemented! Changes may have no effect.')

        p = self.param
        # Set some model defaults
        p.R = 2500.
        p.alpha = 1e-3
        p.beta = 10.
        p.mu = 200.
        p.tau = 1.
        p.phia = 0.
        p.z1 = None
        p.z2 = None
        # Read in the arguments
        if arg is not None:
            p.set(arg)
        if kwarg:
            p.set(kwarg)
        
        # Test z1 and z2
        if p.z1 is None or p.z2 is None:
            raise Exception('FiniteIon1D.init_param(): z1 and z2 parameters are required.')
        elif not (0 < p.z1 < p.z2 < 1):
            raise Exception('FiniteIon1D.init_param(): z1 and z2 parameters do not obey: 0 < z1 < z2 < 1.')
            
        # Force the omega value last (just in case the user tried to write it in kwarg)
        p.omega = 1./(p.z2-p.z1)


    def init_grid(self, d, r=None):
        """Initialize the grid and related parameters
    M.init_grid( z )
        OR
    M.init_grid( d )
        OR
    M.init_grid( (d0, d1, d2) )
        OR
    M.init_grid( d, (r0, r1, r2, r3) )

** Required arguments: 
    z
If the only argument is a numpy array, it will be treated as the node locations to
use.  Be warned: if z1 and z2 values are not found in z, an Exception will be raised.
    
    d OR d=(d0, d1, d2)
If d is a single scalar value, it is interpreted as the approximate uniform node 
spacing everywhere in the solution domain.  If d is an array-like type, it is
expected to contain three elements that will be interpreted as the node spacing 
in sub-domains 
    d[0] : 0 <= z < z1 (upstream of the reaction zone), 
    d[1] : z1 <= z <= z2 (in the reaction zone),
    d[2] : z2 <= z <= 0 (downstream of the reaction zone)

The actual node spacing will be adjusted to allow the node 

** Optional arguments: 
    r = (r0, r1, r2, r3)
Regardless of how many d-values are supplied, the optional r[X] keyword 
arguments enhance the relative node spacing at the boundaries of the sub-domains
(see diagram).  
    r0 : z=0 (upstream boundary)
    r1 : z=z1 (beginning of the reaction region)
    r2 : z=z2 (end of the reaction region)
    r3 : z=1 (domain end)

** How is the grid calculated?
The domain [0,1] is divided into three sub-domains formed by the reaction region
z1 and z2.  In each a cubic grid (see the ion1d.cubicgrid() function) is used 
to construct a piece-wise continuous distribution of node points.  The node 
spacing is adjusted at the interfaces z1 and z2 so that there are no sharp 
discontinuities in node spacing.

The diagram below shows the sub-domains and the arguments that affect them.
    
 r0   d0    r1       d1         r2              d2                  r3
 |          |                   |                                   |
 +----------+-------------------+-----------------------------------+
z=0        z=z1                z=z2                                z=1

The node spacing in each of the sub-domains will not always be exactly what is 
specified.  The algorithm will adjust the actual spacing so that nodes always 
fall exactly on z=z1 and z=z2.  The algorithm stores the indices corresponding 
to z=z1 and z=z2 in k[0] and k[1] respectively.

At the interfaces, the nominal grid spacing will be the average of that of the
neighboring sub-domains.  That can be modified by assinging a value to the 
appropriate rX parameter.  For example, the nominal node spacing at z=z1 is 
calculated r1 * 0.5 * (d0 + d1), so r1 = 1 does not affect the grid spacing, but
r1 = 0.5 would double the node density.

It should be emphasized that the actual grid spacing will vary significantly to 
prevent discontinuities and to accommodate the r parameters.

** What does a raised Exception mean?
Grid generation can fail if the cubic function is forced into non-monotonic 
behaviors (if the node locations are not strictly increasing).  This condition 
is automatically detected by the cubicgrid() function, but the remedy may not 
be obvious.  This problem is likely when there are neighboring regions with 
strongly dissimilar grid spacing, so it can be remedied by experimenting with
more uniform grid spacings or by experimenting with different r-values.
"""
        # Check to see if a grid already exists
        if self.initstate > 0:
            print('INIT_GRID WARNING::The system already appears to have a grid.  Overwriting.')
            Ion1D.__init__(self, initstate=0)
            self.k = None
            
        # Point to param for easier notation
        p = self.param

        # If d is a numpy array, it is an explicit grid definition
        if isinstance(d, np.ndarray):
            # Find z1 and z2
            k0 = d.searchsorted(p.z1)
            if d[k0] != p.z1:
                raise Exception('FiniteIon1D.init_grid(): Did not find z1 in explicit grid definition.')
            k1 = d.searchsorted(p.z2)
            if d[k1] != p.z2:
                raise Exception('FiniteIon1D.init_grid(): Did not find z2 in explicit grid definition.')
            self.z = d
            self.k = [k0, k1]
            self.initstate=1
            return
            
        # Assign spacing to each of the sub-domains
        # If d is an array-like, 
        if hasattr(d, '__iter__'):
            try:
                d0,d1,d2 = d
                d0 = float(d0)
                d1 = float(d1)
                d2 = float(d2)
            except:
                raise Exception('Multiple grid distances should be a three-element array-like of floats')
        # If d is a scalar
        else:
            try:
                d0 = d1 = d2 = float(d)
            except:
                raise Exception('If d is a scalar, it must be convertible to a float')
        # Assign relative spacing to each of the sub-domain boundaries
        if r is None:
            r0 = r1 = r2 = r3 = 1.
        else:
            try:
                r0,r1,r2,r3 = r
                r0 = float(r0)
                r1 = float(r1)
                r2 = float(r2)
                r3 = float(r3)
            except:
                raise Exception('If r is specified, it must be a four-element array-like of floats')
        
        # Modify the nominal grid spacing to arrive at element counts
        N1 = int(np.ceil(p.z1 / d0))
        N2 = int(np.ceil((p.z2-p.z1) / d1))
        N3 = int(np.ceil((1.-p.z2) / d2))
        
        # Calculate the spacing at the two interfaces
        d01 = r1 * 0.5 * (d0+d1)
        d12 = r2 * 0.5 * (d1+d2)
        
        try:
            zz1 = p.z1*cubicgrid(N1, r0, d01/d0, stop=False)
        except:
            raise Exception('These settings caused the up-stream zone (0<=z<z1) to be non-monotonic.  Try new values for d0, d1, or r1.')
        try:
            zz2 = p.z1 + (p.z2-p.z1)*cubicgrid(N2, d01/d1, d12/d1, stop=False)
        except:
            raise Exception('These settings caused the reaction zone (z1<=z<z2) to be non-monotonic.  Try new values for d or r.')
        try:
            zz3 = p.z2 + (1.-p.z2)*cubicgrid(N3, d12/d2, r3)
        except:
            raise Exception('These settings caused the down-stream zone (z2<=z<=1) to be non-monotonic.  Try new values for d1, d2, or r2.')
            
        self.z = np.concatenate((zz1,zz2,zz3))
        self.k = [N1, N1+N2]
        self.initstate = 1

    def init_mat(self):
        """Construct the solution matrices/vectors C, L, and Q."""
        
        if self.initstate < 1:
            raise Exception('INIT_MAT::Failed.  Run INIT_GRID() first.')
        elif self.initstate > 1:
            print('INIT_MAT WARNING::Matrices already generated. Overwriting.')
            Ion1D.__init__(self, initstate = 1)
        
        p = self.param
        
        # How big are the tensors?
        N = 3*self.z.size
        # initialize CLQ
        self.C = np.zeros((N,))
        self.L = spn.SparseN((N,N))
        self.Q = spn.SparseN((N,N,N))
        
        # calculate the square of alpha
        aa = p.alpha*p.alpha
        
        # Loop over the internal nodes
        for k in range(1,self.z.size-1):
            etak = k
            nuk = k + self.z.size
            phik = k + 2*self.z.size
            # Finite differences
            dz10 = self.z[k] - self.z[k-1]
            dz21 = self.z[k+1] - self.z[k]
            dz20 = dz10 + dz21
            
            ap = - dz21 / (dz10 * dz20)
            bp = (dz21 - dz10)/(dz10 * dz21)
            cp = dz10 / (dz20 * dz21)
            
            app = 2 / (dz10 * dz20)
            bpp = -2 / (dz10 * dz21)
            cpp = 2 / (dz20 * dz21)
            
            # Calculate the electric reynolds number
            Re = p.R / (p.mu * p.tau)
            
            self.L[etak,etak-1] = -ap + app/p.R
            self.L[etak,etak] = -bp + bpp/p.R
            self.L[etak,etak+1] = -cp + cpp/p.R
            
            self.L[nuk,nuk-1] = -ap + app/Re
            self.L[nuk,nuk] = -bp + bpp/Re
            self.L[nuk,nuk+1] = -cp + cpp/Re
            
            self.L[phik,phik-1] = aa * app
            self.L[phik,phik] = aa * bpp
            self.L[phik,phik+1] = aa * cpp
            self.L[phik,etak] = 1.
            self.L[phik,nuk] = -1.
            
            self.Q[etak,etak,nuk] = -p.beta
            
            self.Q[nuk,etak,nuk] = -p.beta
            
            self.Q[etak,etak-1,phik-1] = ap*ap * p.tau/p.R
            self.Q[etak,etak,phik-1] = (bp*ap + app) * p.tau/p.R
            self.Q[etak,etak+1,phik-1] = cp*ap * p.tau/p.R
            self.Q[etak,etak-1,phik] = ap*bp * p.tau/p.R
            self.Q[etak,etak,phik] = (bp*bp + bpp) * p.tau/p.R
            self.Q[etak,etak+1,phik] = cp*bp * p.tau/p.R
            self.Q[etak,etak-1,phik+1] = ap*cp * p.tau/p.R
            self.Q[etak,etak,phik+1] = (bp*cp + cpp) * p.tau/p.R
            self.Q[etak,etak+1,phik+1] = cp*cp * p.tau/p.R

            self.Q[nuk,nuk-1,phik-1] = -ap*ap / Re
            self.Q[nuk,nuk,phik-1] = -(bp*ap + app) / Re
            self.Q[nuk,nuk+1,phik-1] = -cp*ap / Re
            self.Q[nuk,nuk-1,phik] = -ap*bp / Re
            self.Q[nuk,nuk,phik] = -(bp*bp + bpp) / Re
            self.Q[nuk,nuk+1,phik] = -cp*bp / Re
            self.Q[nuk,nuk-1,phik+1] = -ap*cp / Re
            self.Q[nuk,nuk,phik+1] = -(bp*cp + cpp) / Re
            self.Q[nuk,nuk+1,phik+1] = -cp*cp / Re
            
            if self.k[0] < k < self.k[1]:
                self.C[etak] = p.omega
                self.C[nuk] = p.omega
                
        # Add adjusted forcing at the edge of the reaction region
        k = self.k[0]
        etak = k
        nuk = etak + self.z.size
        # Scale by the fraction of the node that belongs to the reaction region
        ss = (self.z[k+1]-self.z[k])/(self.z[k+1]-self.z[k-1])
        self.C[nuk] = self.C[etak] =  ss * p.omega

        k = self.k[1]
        etak = k
        nuk = etak + self.z.size
        # Scale by the fraction of the node that belongs to the reaction region
        ss = (self.z[k]-self.z[k-1])/(self.z[k+1]-self.z[k-1])
        self.C[nuk] = self.C[etak] =  ss * p.omega

        # Add boundary conditions
        etak = 0
        nuk = etak + self.z.size
        phik = nuk + self.z.size
        self.L[etak,etak] = 1        # eta(0) = 0
        self.L[nuk,nuk] = 1          # nu(0) = 0
        self.L[phik,phik] = 1        # phi(0) = phia
        self.C[phik] = -p.phia
        
        etak = self.z.size-1
        nuk = etak + self.z.size
        phik = nuk + self.z.size
        self.L[etak,etak] = 1        # eta(1) = 0
        self.L[nuk,nuk] = 1          # nu(1) = 0
        self.L[phik,phik] = 1        # phi(1) = 0
        
        # Finally, generate QQT
        self.QQT = self.Q + self.Q.transpose(1,2)
        
        self.initstate = 2

class AnchoredFiniteIon1D(Ion1D):
    """Like FiniteIon1D, but with formation starting at z=0.
    
An execution of the model might appear
>>> M = FiniteIon1D()
>>> M.init_param( z1, ... other params ...)
>>> M.init_grid( ... )
>>> M.init_mat()
>>> M.init_solution()
>>> while not M.test_solution():
...     M.step_solution()
Creates a model with a uniform ion generation region between 0 and z1 with
ion generation rate 1/z1.  By necessity, 0 < z1 < 1.
"""
    def __init__(self):
        # Initialize the general members
        Ion1D.__init__(self)
        # Add an attribute for keeping track of important indices
        self.k = None
        
    def init_param(self, arg=None, **kwarg):
        """FiniteIon1D model parameter initialization
    M.init_param(z1=z1, ...)
        OR
    M.init_param( param_obj )
        OR
    M.init_param({'z1':z1, ...})
    
init_param() accepts individual keyword, value pairs or an IonParam object, or
a dictionary with keyword, value pairs.

Required parameters:
z1          This is the location where the formation region ends.
            init_param enforces  0 < z1 < 1
            
Optional parameters and their defaults:
R           Positive ion Reynolds number (2500.)
alpha       Dimensionless Debye length (1e-3)
beta        Dimensionless inverse recombination length (10.)
mu          Negative-to-positive species mobility ratio (200.)
tau         Negative-to-positive temperature ratio (1.)
phia        Dimensionless applied voltage (0.)

Derived parameters:
omega       Formation rate = 1./z1.  User values are overwritten.
"""
        if self.initstate > 0:
            print('INIT_PARAM::WARNING: Parameters already seem to be implemented! Changes may have no effect.')

        p = self.param
        # Set some model defaults
        p.R = 2500.
        p.alpha = 1e-3
        p.beta = 10.
        p.mu = 200.
        p.tau = 1.
        p.phia = 0.
        p.z1 = None
        # Read in the arguments
        if arg is not None:
            p.set(arg)
        if kwarg:
            p.set(kwarg)
        
        # Test z1 and z2
        if p.z1 is None:
            raise Exception('AnchoredFiniteIon1D.init_param(): z1 parameter is required.')
        elif not (0 < p.z1 < 1):
            raise Exception('FiniteIon1D.init_param(): z1 parameter does not obey: 0 < z1 < 1.')
            
        # Force the omega value last (just in case the user tried to write it in kwarg)
        p.omega = 1./(p.z1)


    def init_grid(self, d, r=None):
        """Initialize the grid and related parameters
    M.init_grid( z )
        OR
    M.init_grid( d )
        OR
    M.init_grid( (d0, d1) )
        OR
    M.init_grid( d, (r0, r1, r2) )

** Required arguments: 
    z
If the only argument is a numpy array, it will be treated as the node locations to
use.  Be warned: if z1 and z2 values are not found in z, an Exception will be raised.
    
    d OR d=(d0, d1)
If d is a single scalar value, it is interpreted as the approximate uniform node 
spacing everywhere in the solution domain.  If d is an array-like type, it is
expected to contain three elements that will be interpreted as the node spacing 
in sub-domains 
    d[0] : 0 <= z < z1 (upstream of the reaction zone), 
    d[1] : z1 <= z <= z2 (in the reaction zone),
    d[2] : z2 <= z <= 0 (downstream of the reaction zone)

The actual node spacing will be adjusted to allow the node 

** Optional arguments: 
    r = (r0, r1, r2)
Regardless of how many d-values are supplied, the optional r[X] keyword 
arguments enhance the relative node spacing at the boundaries of the sub-domains
(see diagram).  
    r0 : z=0 (upstream boundary)
    r1 : z=z1 (beginning of the reaction region)
    r2 : z=z2 (end of the reaction region)
    r3 : z=1 (domain end)

** How is the grid calculated?
The domain [0,1] is divided into three sub-domains formed by the reaction region
z1 and z2.  In each a cubic grid (see the ion1d.cubicgrid() function) is used 
to construct a piece-wise continuous distribution of node points.  The node 
spacing is adjusted at the interface z1 so that there are no sharp 
discontinuities in node spacing.

The diagram below shows the sub-domains and the arguments that affect them.
    
 r0            d0               r1              d1                  r2
 |                              |                                   |
 +------------------------------+-----------------------------------+
z=0                            z=z1                                z=1

The node spacing in each of the sub-domains will not always be exactly what is 
specified.  The algorithm will adjust the actual spacing so that nodes always 
fall exactly on z=z1.  The algorithm stores the index corresponding to z=z1 
in k[0].

At the interfaces, the nominal grid spacing will be the average of that of the
neighboring sub-domains.  That can be modified by assinging a value to the 
appropriate rX parameter.  For example, the nominal node spacing at z=z1 is 
calculated r1 * 0.5 * (d0 + d1), so r1 = 1 does not affect the grid spacing, but
r1 = 0.5 would double the node density.

It should be emphasized that the actual grid spacing will vary significantly to 
prevent discontinuities and to accommodate the r parameters.

** What does a raised Exception mean?
Grid generation can fail if the cubic function is forced into non-monotonic 
behaviors (if the node locations are not strictly increasing).  This condition 
is automatically detected by the cubicgrid() function, but the remedy may not 
be obvious.  This problem is likely when there are neighboring regions with 
strongly dissimilar grid spacing, so it can be remedied by experimenting with
more uniform grid spacings or by experimenting with different r-values.
"""
        # Check to see if a grid already exists
        if self.initstate > 0:
            print('INIT_GRID WARNING::The system already appears to have a grid.  Overwriting.')
            Ion1D.__init__(self, initstate=0)
            self.k = None
            
        # Point to param for easier notation
        p = self.param

        # If d is a numpy array, it is an explicit grid definition
        if isinstance(d, np.ndarray):
            # Find z1 and z2
            k0 = d.searchsorted(p.z1)
            if d[k0] != p.z1:
                raise Exception('FiniteIon1D.init_grid(): Did not find z1 in explicit grid definition.')
            self.z = d
            self.k = [k0]
            self.initstate=1
            return
            
        # Assign spacing to each of the sub-domains
        # If d is an array-like, 
        if hasattr(d, '__iter__'):
            try:
                d0,d1 = d
                d0 = float(d0)
                d1 = float(d1)
            except:
                raise Exception('Multiple grid distances should be a two-element array-like of floats')
        # If d is a scalar
        else:
            try:
                d0 = d1 = float(d)
            except:
                raise Exception('If d is a scalar, it must be convertible to a float')
        # Assign relative spacing to each of the sub-domain boundaries
        if r is None:
            r0 = r1 = r2 = 1.
        else:
            try:
                r0,r1,r2 = r
                r0 = float(r0)
                r1 = float(r1)
                r2 = float(r2)
            except:
                raise Exception('If r is specified, it must be a three-element array-like of floats')
        
        # Modify the nominal grid spacing to arrive at element counts
        N0 = int(np.ceil(p.z1 / d0))
        N1 = int(np.ceil((1-p.z1) / d1))
        
        # Calculate the spacing at the interface
        d01 = r1 * 0.5 * (d0+d1)
        
        try:
            zz0 = p.z1*cubicgrid(N0, r0, d01/d0, stop=False)
        except:
            raise Exception('These settings caused the up-stream zone (0<=z<z1) to be non-monotonic.  Try new values for d0, d1, or r1.')
        try:
            zz1 = p.z1 + (1.-p.z1)*cubicgrid(N1, d01/d1, r2, stop=False)
        except:
            raise Exception('These settings caused the reaction zone (z1<=z<=1) to be non-monotonic.  Try new values for d or r.')
            
        self.z = np.concatenate((zz0,zz1))
        self.k = [N0]
        self.initstate = 1

    def init_mat(self):
        """Construct the solution matrices/vectors C, L, and Q."""
        
        if self.initstate < 1:
            raise Exception('INIT_MAT::Failed.  Run INIT_GRID() first.')
        elif self.initstate > 1:
            print('INIT_MAT WARNING::Matrices already generated. Overwriting.')
            Ion1D.__init__(self, initstate = 1)
        
        p = self.param
        
        # How big are the tensors?
        N = self.z.size
        # initialize CLQ
        self.C = np.zeros((3*N,))
        self.L = spn.SparseN((3*N,3*N))
        self.Q = spn.SparseN((3*N,3*N,3*N))
        
        # calculate the square of alpha
        aa = p.alpha*p.alpha
        # Calculate the electric reynolds number
        Re = p.R / (p.mu * p.tau)
            
        # Loop over the internal nodes
        for k in range(1,self.z.size-1):
            etak = k
            nuk = etak + N
            phik = nuk + N
            # Finite differences
            dz10 = self.z[k] - self.z[k-1]
            dz21 = self.z[k+1] - self.z[k]
            dz20 = dz10 + dz21
            
            ap = - dz21 / (dz10 * dz20)
            bp = (dz21 - dz10)/(dz10 * dz21)
            cp = dz10 / (dz20 * dz21)
            
            app = 2 / (dz10 * dz20)
            bpp = -2 / (dz10 * dz21)
            cpp = 2 / (dz20 * dz21)
            
            self.L[etak,etak-1] = -ap + app/p.R
            self.L[etak,etak] = -bp + bpp/p.R
            self.L[etak,etak+1] = -cp + cpp/p.R
            
            self.L[nuk,nuk-1] = -ap + app/Re
            self.L[nuk,nuk] = -bp + bpp/Re
            self.L[nuk,nuk+1] = -cp + cpp/Re
            
            self.L[phik,phik-1] = aa * app
            self.L[phik,phik] = aa * bpp
            self.L[phik,phik+1] = aa * cpp
            self.L[phik,etak] = 1.
            self.L[phik,nuk] = -1.
            
            self.Q[etak,etak,nuk] = -p.beta
            
            self.Q[nuk,etak,nuk] = -p.beta
            
            self.Q[etak,etak-1,phik-1] = ap*ap * p.tau/p.R
            self.Q[etak,etak,phik-1] = (bp*ap + app) * p.tau/p.R
            self.Q[etak,etak+1,phik-1] = cp*ap * p.tau/p.R
            self.Q[etak,etak-1,phik] = ap*bp * p.tau/p.R
            self.Q[etak,etak,phik] = (bp*bp + bpp) * p.tau/p.R
            self.Q[etak,etak+1,phik] = cp*bp * p.tau/p.R
            self.Q[etak,etak-1,phik+1] = ap*cp * p.tau/p.R
            self.Q[etak,etak,phik+1] = (bp*cp + cpp) * p.tau/p.R
            self.Q[etak,etak+1,phik+1] = cp*cp * p.tau/p.R

            self.Q[nuk,nuk-1,phik-1] = -ap*ap / Re
            self.Q[nuk,nuk,phik-1] = -(bp*ap + app) / Re
            self.Q[nuk,nuk+1,phik-1] = -cp*ap / Re
            self.Q[nuk,nuk-1,phik] = -ap*bp / Re
            self.Q[nuk,nuk,phik] = -(bp*bp + bpp) / Re
            self.Q[nuk,nuk+1,phik] = -cp*bp / Re
            self.Q[nuk,nuk-1,phik+1] = -ap*cp / Re
            self.Q[nuk,nuk,phik+1] = -(bp*cp + cpp) / Re
            self.Q[nuk,nuk+1,phik+1] = -cp*cp / Re
            
            if k < self.k[0]:
                self.C[etak] = p.omega
                self.C[nuk] = p.omega
                

        k = self.k[0]
        etak = k
        nuk = etak + self.z.size
        # Scale by the fraction of the node that belongs to the reaction region
        ss = (self.z[k]-self.z[k-1])/(self.z[k+1]-self.z[k-1])
        self.C[nuk] = self.C[etak] =  ss * p.omega

        # Add boundary conditions
        etak = 0
        nuk = etak + self.z.size
        phik = nuk + self.z.size
        self.L[etak,etak] = 1        # eta(0) = 0
        self.L[nuk,nuk] = 1          # nu(0) = 0
        self.L[phik,phik] = 1        # phi(0) = phia
        self.C[phik] = -p.phia
        
        etak = self.z.size-1
        nuk = etak + self.z.size
        phik = nuk + self.z.size
        self.L[etak,etak] = 1        # eta(1) = 0
        self.L[nuk,nuk] = 1          # nu(1) = 0
        self.L[phik,phik] = 1        # phi(1) = 0
        
        # Finally, generate QQT
        self.QQT = self.Q + self.Q.transpose(1,2)
        
        self.initstate = 2


class PostIon1D(Ion1D):
    """A special class for dealing with saving and loading the results of prior model runs

The PostIon1D is just like any Ion1D model, but it contains none of the 
attributes needed to initialize or perform a soluiton; it only has tools for 
loading, plotting, and performing post-processing on an existing solution.

PostIon1D instances can be built from the results of an existing Ion1D object, 
or they can be loaded from the results saved earlier.

    M = PostIon1D( ExistingIon1DObject )
        OR
    M = PostIon1D( '/path/to/data/archive.tar' )
    
The intention is that attributes be added freely to the object so they can be
saved and reloaded later.

** FORMAT **
All of the PostIon1D object attributes that can be serialized in a json format
are written explicitly to the "post.json" file in the root of the output 
tarball.  The file forms a dictionary whose members are interpreted as the
attributes of the PostIon1D instance being constructed.

If a dictionary member has a string value that is found to be the name of a 
tarball member file, that file is treated as a numpy ndarray .npy file.  The
string value is replaced with the numpy array and loaded into PostIon1D 
instance.

There is also a special "model" attribute, which is the class that was 
originally used to initialize the PostIon1D instance.  When it is saved, it was
converted into the class's __name__ string.  After loading is complete, the 
value in the model member is used to search the ion1d module.  If a member's 
name matches the string the string is overwritten with that object.  The intent
is that the string will match the name of an Ion1D subclass, and that the
model member will be set to that subclass.

The "param" attribute should have been saved as a dictionary of numeric 
parameters used to construct the model.  After being loaded, that dictionary
is converted into an IonParam object using the IonParam.__init__() method.

All other values with type str, int, float, list, tuple, or dict are loaded 
verbatim as attributes of the PostIon1D instance.

** WARNING **
There is no protection against overwriting the methods of a PostIon1D instance.
For example, a badly constructed post.json file might have an entry 
'save':'FOOLED YOU!' that would overwrite the save() method with a string that 
emphasizes the nature of the problem.
"""
    def __init__(self, source, verbose=False):
        # If initializing from another model
        if issubclass(type(source), Ion1D):
            # Verify that the model actually has a solution
            if source.initstate < 3:
                raise Exception('The solution for the Ion1D model is not yet available')
            # Perform a thin copy
            # All variables will only point to the parent data
            self.param = source.param
            
            self.z = source.z
            
            self.eta = source.eta
            self.nu = source.nu
            self.phi = source.phi
            
            self.etaE = source.etaE
            self.nuE = source.nuE
            self.phiE = source.phiE

            self.model = type(source)
            
            
        elif isinstance(source, str):
            # Treat the source string as a path to tar archive
            # Force absolute paths
            source = os.path.abspath(source)
            # Verify that the source exists
            if not os.path.isfile(source):
                # If not, look for different extensions
                path,filename = os.path.split(source)
                contents = os.listdir(path)
                found = False
                for candidate in contents:
                    if candidate.startswith(filename):
                        found = True
                        source=os.path.join(path,candidate)
                if not found:
                    raise Exception('File not found: ' + source)
            if verbose:
                print('Loading archive: ' + source)
            
            # OK, let's go
            with tempfile.TemporaryDirectory() as tempdir:
                with tarfile.open(source, 'r') as arch_fd:
                    if verbose:
                        print('Expanding archive into: ' + tempdir)
                    arch_fd.extractall(path=tempdir)
                    
                if verbose:
                    print('Loading member: post.json')
                # Load the json file with the raw data
                try:
                    with open(os.path.join(tempdir, 'post.json'),'r') as ff:
                        post = json.load(ff)
                except:
                    raise Exception('Failed to parse the post json file: ' + postfile)
                    
                for key,value in post.items():
                    if isinstance(value,str):
                        npyfile = os.path.join(tempdir,value)
                        if os.path.isfile(npyfile):
                            if verbose:
                                print('Loading numpy array from: ' + value)
                            post[key] = np.load(npyfile)
                        
                        self.__dict__[key] = value
                    
            # Read in the result to the Post object
            self.__dict__.update(post)
            # Finally, clean up some of the standard attribute types...
            # Convert the parameters to an IonParam object if able
            if isinstance(self.param, dict):
                self.param = IonParam(**self.param)
            else:
                print('LOAD_POST::WARNING: Did not find a valid parameter dictionary')
            # If the model name string appears in the ion1d module, use it.
            if isinstance(self.model,str) and self.model in _ion1d.__dict__:
                self.model = _ion1d.__dict__[self.model]
            else:
                print('LOAD_POST::WARNING: Did not find the model: ' + repr(self.model))
            


    def save(self, target, overwrite=False, compression='bz2', verbose=False):
        """Save the PostIon1D object
    M.save(filename)

The save() method creates a tarball archive that can be used to reconstitute
the PostIon1D object later.  The compression keyword parameter is a string that
allows the user to opt for different compression algorithms.  Valid strings are
listed below.

Nominally, the filename should be a path to a file with no appended extension.  
The save() method will append the correct extension if it is not found.  The
extension is based on the compression method.

compression extension   method
'none'      .tar        none-tarball only
'bz2'       .tar.bz2    bzip2 compression
'gz'        .tar.gz     gzip compression

** FORMAT **
All of the PostIon1D object attributes that can be serialized in a json format
are written explicitly to the "post.json" file in the root of the output 
tarball.  Numpy arrays are saved as separate files in the tarball named by their
attribute name with the .npy extension appended, then the array is replaced by
its filename in the json file.  For example, in "post.json" struct, the 'z'
attribute would appear ... "z":"z.npy" ... and there would be a file named z.npy
in the root of the tarball.

There is also a special "model" attribute, which is the class that was 
originally used to initialize the PostIon1D instance.  When it is saved, it is
converted into the class's __name__ string.

The "param" attribute, which is an instance of IonParam, is converted to a dict
using the object's asdict() method, and stored in the json file.

Finally, any other attributes that are not str, int, float, dict, list or numpy
ndarrays are replaced with the output of repr().  
"""
        # Initialize the extension to append to the target file
        extension = '.tar'
        # Initialize the tar mode string
        tarmode = 'w:'
        
        # Case out the compression mode, and assign the target file extension
        # and the tar mode string.
        if compression == 'none' or compression is None:
            extension = '.tar'
            tarmode = 'w:'
        elif compression == 'gz':
            extension = '.tar.gz'
            tarmode = 'w:gz'
        elif compression == 'bz2':
            extension = '.tar.bz2'
            tarmode = 'w:bz2'
        else:
            raise Exception('Unexpected value for the compression keyword: {:s}\n  Expected one of: {:s}'.format(\
                    compression, repr(COMPRESSION_ALLOWED)))
        
        # Ok, that's taken care of.  Now, name some directories
        # The target should have the proper extension and it should be a full
        # path.  I don't like relative paths... they're so... relative.
        # Yup, coding for LONG hours during a COVID-19 pandemic inspires some
        # weird comments.
        if not target.endswith(extension):
            target += extension
        target = os.path.abspath(target)

        if verbose:
            print('Writing to file: ' + target)

        # Check to see if the destination directory already exists
        if os.path.exists(target):
            if overwrite:
                if verbose:
                    print('Overwriting existing file.')
                os.remove(target)
            else:
                raise Exception('The target file already exists: ' + target)

        with tempfile.TemporaryDirectory() as tempdir:
            if verbose:
                print('Staging files in directory: ' + tempdir)
            # Make a duplicate of the post dict.  As we go, we will overwrite
            # Numpy arrays with their file names
            posttemp = self.__dict__.copy()

            # Create the archive
            with tarfile.open(target, 'w:' + compression) as arch_fd:
                for key,value in posttemp.items():
                    if isinstance(value,np.ndarray):
                        npfile = key + '.npy'
                        npfile_full = os.path.join(tempdir, npfile)
                        np.save(npfile_full, value)
                        arch_fd.add(npfile_full, arcname=npfile)
                        posttemp[key] = npfile
                        os.remove(npfile_full)
                    # If the attribute is uninitialized, don't save it
                    elif isinstance(value,IonParam):
                        posttemp[key] = value.asdict()
                    # Catch the model type (or others too... why not?)
                    elif isinstance(value,type):
                        posttemp[key] = value.__name__
                    # Use a catch-all for other non-serializable entries
                    elif not isinstance(value,(str,int,float,dict,list,tuple)):
                        posttemp[key] = repr(value)
                    elif value is None:
                        del posttemp[key]
                    
                # Write the post dictionary
                postfile = 'post.json'
                postfile_full = os.path.join(tempdir, postfile)
                with open(postfile_full, 'w') as ff:
                    json.dump(posttemp, ff, skipkeys=True)
                arch_fd.add(postfile_full, arcname=postfile)
                os.remove(postfile_full)


    def expand_post(self):

        N = self.z.size
        # Point to the parameters
        p = self.param
            
        # Calculate a couple of intermediate parameters
        Re = p.R / (p.mu * p.tau)   # Electric R
        aa = p.alpha * p.alpha      # alpha squared
        
        # Initialize a solution matrix to perform the voltage perturbation
        # anlaysis.
        A = np.zeros((3*N,3*N))
        C = np.zeros((3*N,))
        
        # First derivatives
        self.d1eta = np.ndarray((N,))
        self.d1nu = np.ndarray((N,))
        self.d1phi = np.ndarray((N,))
        # Second derivatives
        self.d2eta = np.ndarray((N,))
        self.d2nu = np.ndarray((N,))
        self.d2phi = np.ndarray((N,))
        
        # Move on to the internal nodes
        for k in range(1,N-1):
            # Calculate the interpolation function derivatives
            dz10 = self.z[k] - self.z[k-1]
            dz21 = self.z[k+1] - self.z[k]
            dz20 = dz10 + dz21
            
            ap = - dz21 / (dz10 * dz20)
            bp = (dz21 - dz10)/(dz10 * dz21)
            cp = dz10 / (dz20 * dz21)
            
            app = 2 / (dz10 * dz20)
            bpp = -2 / (dz10 * dz21)
            cpp = 2 / (dz20 * dz21)
            
            # Calculate eta_d, nu_d, and phi_d
            e_d = ap*self.eta[k-1] + bp*self.eta[k] + cp*self.eta[k+1]
            n_d = ap*self.nu[k-1] + bp*self.nu[k] + cp*self.nu[k+1]
            p_d = ap*self.phi[k-1] + bp*self.phi[k] + cp*self.phi[k+1]
            # Calculate eta_dd, nu_dd, and phi_dd
            e_dd = app*self.eta[k-1] + bpp*self.eta[k] + cpp*self.eta[k+1]
            n_dd = app*self.nu[k-1] + bpp*self.nu[k] + cpp*self.nu[k+1]
            p_dd = app*self.phi[k-1] + bpp*self.phi[k] + cpp*self.phi[k+1]
            
            self.d1eta[k] = e_d
            self.d1nu[k] = n_d
            self.d1phi[k] = p_d
            
            self.d2eta[k] = e_dd
            self.d2nu[k] = n_dd
            self.d2phi[k] = p_dd
            
            # For convenience, point to eta[k], nu[k] and phi[k]
            e_ = self.eta[k]
            n_ = self.nu[k]
            p_ = self.phi[k]
            
            eta_k = k
            nu_k = eta_k + N
            phi_k = nu_k + N
            
            # Calculate the solution matrix for the perturbation analysis
            A[eta_k, eta_k-1] = app/p.R - ap + p.tau/p.R*(ap*p_d)
            A[eta_k, eta_k] = bpp/p.R - bp + p.tau/p.R*(bp*p_d + p_dd) - p.beta*n_
            A[eta_k, eta_k+1] = cpp/p.R - cp + p.tau/p.R*(cp*p_d)
            A[eta_k, nu_k] = -p.beta*e_
            A[eta_k, phi_k-1] = p.tau/p.R*(ap*e_d + app*e_)
            A[eta_k, phi_k] = p.tau/p.R*(bp*e_d + bpp*e_)
            A[eta_k, phi_k+1] = p.tau/p.R*(cp*e_d + cpp*e_)

            A[nu_k, nu_k-1] = app/Re - ap - (ap*p_d)/Re
            A[nu_k, nu_k] = bpp/Re - bp - (bp*p_d + p_dd)/Re - p.beta*e_
            A[nu_k, nu_k+1] = cpp/Re - cp - (cp*p_d)/Re
            A[nu_k, eta_k] = -p.beta*n_
            A[nu_k, phi_k-1] = -(ap*n_d + app*n_)/Re
            A[nu_k, phi_k] = -(bp*n_d + bpp*n_)/Re
            A[nu_k, phi_k+1] = -(cp*n_d + cpp*n_)/Re

            A[phi_k, phi_k-1] = aa*app
            A[phi_k, phi_k] = aa*bpp
            A[phi_k, phi_k+1] = aa*cpp
            A[phi_k, eta_k] = 1
            A[phi_k, nu_k] = -1
            
        # Deal with the end-points
        # Start at the boundary node z=0
        dz10 = self.z[1] - self.z[0]
        dz21 = self.z[2] - self.z[1]
        dz20 = dz21 + dz10
        # Use only the two boundary nodes to construct the derivative
        ap = -(dz10 + dz20)/(dz20 * dz10)
        bp = dz20/(dz10*dz21)
        cp = -dz10/(dz20*dz21)

        app = 2 / (dz10 * dz20)
        bpp = -2 / (dz10 * dz21)
        cpp = 2 / (dz20 * dz21)
        
        self.d1eta[0] = ap*self.eta[0] + bp*self.eta[1] + cp*self.eta[2]
        self.d1nu[0] = ap*self.nu[0] + bp*self.nu[1] + cp*self.nu[2]
        self.d1phi[0] = ap*self.phi[0] + bp*self.phi[1] + cp*self.phi[2]
        
        self.d2eta[0] = app*self.eta[0] + bpp*self.eta[1] + cpp*self.eta[2]
        self.d2nu[0] = app*self.nu[0] + bpp*self.nu[1] + cpp*self.nu[2]
        self.d2phi[0] = app*self.phi[0] + bpp*self.phi[1] + cpp*self.phi[2]

        A[0,0] = 1
        A[N,N] = 1
        A[2*N,2*N] = 1
        C[2*N] = 1

        # Finish at the boundary node z=1
        dz10 = self.z[-2] - self.z[-3]
        dz21 = self.z[-1] - self.z[-2]
        dz20 = dz21 + dz10
        ap = dz21/(dz20*dz10)
        bp = -dz20/(dz10*dz21)
        cp = (dz20 + dz21)/(dz20*dz21)

        # Reach in one extra node to construct the second derivative
        app = 2 / (dz10 * dz20)
        bpp = -2 / (dz10 * dz21)
        cpp = 2 / (dz20 * dz21)

        self.d1eta[-1] = ap*self.eta[-3] + bp*self.eta[-2] + cp*self.eta[-1]
        self.d1nu[-1] = ap*self.nu[-3] + bp*self.nu[-2] + cp*self.nu[-1]
        self.d1phi[-1] = ap*self.phi[-3] + bp*self.phi[-2] + cp*self.phi[-1]
        
        self.d2eta[-1] = app*self.eta[-3] + bpp*self.eta[-2] + cpp*self.eta[-1]
        self.d2nu[-1] = app*self.nu[-3] + bpp*self.nu[-2] + cpp*self.nu[-1]
        self.d2phi[-1] = app*self.phi[-3] + bpp*self.phi[-2] + cpp*self.phi[-1]
        
        A[N-1,N-1] = 1
        A[2*N-1, 2*N-1] = 1
        A[3*N-1, 3*N-1] = 1
        
        # Solve the perturbation problem
        X1 = np.linalg.solve(A,C)
        self.eta1 = X1[:N]
        self.nu1 = X1[N:2*N]
        self.phi1 = X1[2*N:]

        # Finally, calculate the derivatives of the perturbation solution
        self.d1eta1 = np.ndarray(self.z.shape)
        self.d1nu1 = np.ndarray(self.z.shape)
        self.d1phi1 = np.ndarray(self.z.shape)
        
        for k in range(1,N-1):
            # Calculate the interpolation function derivatives
            dz10 = self.z[k] - self.z[k-1]
            dz21 = self.z[k+1] - self.z[k]
            dz20 = dz10 + dz21
            
            ap = - dz21 / (dz10 * dz20)
            bp = (dz21 - dz10)/(dz10 * dz21)
            cp = dz10 / (dz20 * dz21)
            
            self.d1eta1[k] = ap*self.eta1[k-1] + bp*self.eta1[k] + cp*self.eta1[k+1]
            self.d1nu1[k] = ap*self.nu1[k-1] + bp*self.nu1[k] + cp*self.nu1[k+1]
            self.d1phi1[k] = ap*self.phi1[k-1] + bp*self.phi1[k] + cp*self.phi1[k+1]
        
        # Deal with the end-points
        # Start at the boundary node z=0
        dz10 = self.z[1] - self.z[0]
        dz21 = self.z[2] - self.z[1]
        dz20 = dz21 + dz10
        ap = -(dz10 + dz20)/(dz20 * dz10)
        bp = dz20/(dz10*dz21)
        cp = -dz10/(dz20*dz21)

        self.d1eta1[0] = ap*self.eta1[0] + bp*self.eta1[1] + cp*self.eta1[2]
        self.d1nu1[0] = ap*self.nu1[0] + bp*self.nu1[1] + cp*self.nu1[2]
        self.d1phi1[0] = ap*self.phi1[0] + bp*self.phi1[1] + cp*self.phi1[2]
        
        # Finish at the boundary node z=1
        dz10 = self.z[-2] - self.z[-3]
        dz21 = self.z[-1] - self.z[-2]
        dz20 = dz21 + dz10
        ap = dz21/(dz20*dz10)
        bp = -dz20/(dz10*dz21)
        cp = (dz20 + dz21)/(dz20*dz21)
        
        self.d1eta1[-1] = ap*self.eta1[-3] + bp*self.eta1[-2] + cp*self.eta1[-1]
        self.d1nu1[-1] = ap*self.nu1[-3] + bp*self.nu1[-2] + cp*self.nu1[-1]
        self.d1phi1[-1] = ap*self.phi1[-3] + bp*self.phi1[-2] + cp*self.phi1[-1]

        self.Fi = self.eta - (1/p.R)*self.d1eta - (p.tau/p.R)*self.eta*self.d1phi
        self.Fe = self.nu - (1/Re)*self.d1nu + (1/Re)*self.nu*self.d1phi
        
        self.Fi1 = self.eta1 - (1/p.R)*self.d1eta1 - (p.tau/p.R)*(self.eta1*self.d1phi + self.eta*self.d1phi1)
        self.Fe1 = self.nu1 - (1/Re)*self.d1nu1 + (1/Re)*(self.nu1*self.d1phi + self.nu*self.d1phi1)
        
        self.J = self.Fi[1] - self.Fe[1]
        self.J1 = self.Fi1[1] - self.Fe1[1]
        

    def diff(self, y, second=False):
        """Return the derivative of the vector, y, on z.
    dydz = P.diff(y)
"""
        if y.shape != self.z.shape:
            raise Exception('The vector size must match the grid size')
        dy = np.ndarray(self.z.shape)
        N = self.z.size
        
        # Move on to the internal nodes
        for k in range(1,N-1):
            # Calculate the interpolation function derivatives
            dz10 = self.z[k] - self.z[k-1]
            dz21 = self.z[k+1] - self.z[k]
            dz20 = dz10 + dz21
            
            ap = - dz21 / (dz10 * dz20)
            bp = (dz21 - dz10)/(dz10 * dz21)
            cp = dz10 / (dz20 * dz21)
            
            app = 2 / (dz10 * dz20)
            bpp = -2 / (dz10 * dz21)
            cpp = 2 / (dz20 * dz21)
            
            dy[k] = ap * y[k-1] + bp * y[k] + cp * y[k+1]
            
        # Deal with the end-points
        # Start at the boundary node z=0
        dz10 = self.z[1] - self.z[0]
        dz21 = self.z[2] - self.z[1]
        dz20 = dz21 + dz10
        # Use only the two boundary nodes to construct the derivative
        ap = -(dz10 + dz20)/(dz20 * dz10)
        bp = dz20/(dz10*dz21)
        cp = -dz10/(dz20*dz21)

        app = 2 / (dz10 * dz20)
        bpp = -2 / (dz10 * dz21)
        cpp = 2 / (dz20 * dz21)
        
        dy[0] = ap * y[0] + bp * y[1] + cp * y[2]
        
        # Finish at the boundary node z=1
        dz10 = self.z[-2] - self.z[-3]
        dz21 = self.z[-1] - self.z[-2]
        dz20 = dz21 + dz10
        ap = dz21/(dz20*dz10)
        bp = -dz20/(dz10*dz21)
        cp = (dz20 + dz21)/(dz20*dz21)

        # Reach in one extra node to construct the second derivative
        app = 2 / (dz10 * dz20)
        bpp = -2 / (dz10 * dz21)
        cpp = 2 / (dz20 * dz21)
        
        dy[-1] = ap * y[-3] + bp * y[-2] + cp * y[-1]
        return dy
